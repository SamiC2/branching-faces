{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un6tNZhrN_3q"
   },
   "source": [
    "# 1. Import the Preprocessed Data\n",
    "Import the pickle file with the preprocessed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSIn8ESYLpB5",
    "outputId": "8ea9e042-c558-494c-e9f8-bd85030f5756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train', 'X_test', 'y_train_userid', 'y_train_pose', 'y_train_expression', 'y_train_eyes', 'y_test_userid', 'y_test_pose', 'y_test_expression', 'y_test_eyes'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pickle_file = 'https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_3/datasets/pickles/preprocessed_faces_data.pkl'\n",
    "response = requests.get(pickle_file)\n",
    "data = pd.read_pickle(io.BytesIO(response.content))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eDFj4qXRNomz"
   },
   "outputs": [],
   "source": [
    "# Collect the data into individual variables\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "\n",
    "y_train_userid = data['y_train_userid']\n",
    "y_train_pose = data['y_train_pose']\n",
    "y_train_expression = data['y_train_expression']\n",
    "y_train_eyes = data['y_train_eyes']\n",
    "\n",
    "y_test_userid = data['y_test_userid']\n",
    "y_test_pose = data['y_test_pose']\n",
    "y_test_expression = data['y_test_expression']\n",
    "y_test_eyes = data['y_test_eyes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will show the number of categories each of our target variables contains to show why we need a TF model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid_an2i', 'userid_at33', 'userid_boland', 'userid_bpm',\n",
       "       'userid_ch4f', 'userid_cheyer', 'userid_choon', 'userid_danieln',\n",
       "       'userid_glickman', 'userid_karyadi', 'userid_kawamura', 'userid_kk49',\n",
       "       'userid_megak', 'userid_mitchell', 'userid_night', 'userid_phoebe',\n",
       "       'userid_saavik', 'userid_steffi', 'userid_sz24', 'userid_tammo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# userid\n",
    "y_train_userid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pose_left', 'pose_right', 'pose_straight', 'pose_up'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pose\n",
    "y_train_pose.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['expression_angry', 'expression_happy', 'expression_neutral',\n",
       "       'expression_sad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expression\n",
    "y_train_expression.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eyes_sunglasses\n",
       "1.0                1180\n",
       "0.0                1160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyes\n",
    "y_train_eyes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above, expression, userid, and pose are categorical target variables, while the eyes target variable is a binary target variable. This will be addressed when creating the layers for the tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYtrr4IDoUAw"
   },
   "source": [
    "# 2. Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because this is using image data, our neural network uses Conv2D and MaxPooling2D shared layers. If the data/model was used for numerical purposes, create shared **Dense** layers instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "zyyus3qUnpkx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, Model\n",
    "\n",
    "# First we build the input layer\n",
    "input_layer = layers.Input(shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), name='input_features')\n",
    "\n",
    "# Shared layers (common across all tasks)\n",
    "# The second layer should be a Conv2D layer built off the input_layer\n",
    "second_layer = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "\n",
    "# The third layer should be a MaxPooling2D layer built off the second layer\n",
    "third_layer = layers.MaxPooling2D((2, 2))(second_layer)\n",
    "\n",
    "# The fourth layer should be a Conv2D layer built off the third layer, could be 64\n",
    "fourth_layer = layers.Conv2D(32, (3, 3), activation='relu')(third_layer) \n",
    "\n",
    "# The fifth layer should be a MaxPooling2D layer built off the fourth layer\n",
    "fifth_layer = layers.MaxPooling2D((2, 2))(fourth_layer)\n",
    "\n",
    "# The sixth layer should be a Conv2D layer built off the fifth layer\n",
    "sixth_layer = layers.Conv2D(32, (3, 3), activation='relu')(fifth_layer)\n",
    "\n",
    "# The seventh layer should be a Flatten layer built off the sixth layer\n",
    "seventh_layer = layers.Flatten()(sixth_layer)\n",
    "\n",
    "# Lastly, build one dense layer before branching to the different y branches\n",
    "dense_shared = layers.Dense(64, activation='relu')(seventh_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAEw8LXNpm-R"
   },
   "outputs": [],
   "source": [
    "# Build the branches for each of the y variables\n",
    "# Include a dense hidden layer in each along with the output layer.\n",
    "# Remember to include the correct number of nodes for the output! - this is derived from the column length of the target variable\n",
    "# each layer gets its owwn dense layer, and then its output layer\n",
    "\n",
    "# userid\n",
    "userid_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "userid_output = layers.Dense(len(y_train_userid.columns), activation='softmax', name='userid_output')(userid_dense)\n",
    "\n",
    "# pose\n",
    "pose_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "pose_output = layers.Dense(len(y_train_pose.columns), activation='softmax', name='pose_output')(pose_dense)\n",
    "\n",
    "# expression\n",
    "expression_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "expression_output = layers.Dense(len(y_train_expression.columns), activation='softmax', name='expression_output')(expression_dense)\n",
    "\n",
    "# eyes\n",
    "eyes_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "eyes_output = layers.Dense(len(y_train_eyes.columns), activation='sigmoid', name='eyes_output')(eyes_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see that the length of the columns are used to create the output layer node counts. And finally in the below cell, we show that we use categorical_crossentropy for categorical target variables, and binary_crossentropy for the binary target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "YMUUccPe2LRK"
   },
   "outputs": [],
   "source": [
    "# Assemble the model\n",
    "model = Model(inputs=input_layer, \n",
    "              outputs=[userid_output, pose_output, expression_output, eyes_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'userid_output': 'categorical_crossentropy', \n",
    "                    'pose_output': 'categorical_crossentropy',\n",
    "                    'expression_output': 'categorical_crossentropy',\n",
    "                    'eyes_output': 'binary_crossentropy'},\n",
    "              metrics={'userid_output': 'accuracy', \n",
    "                       'pose_output': 'accuracy',\n",
    "                       'expression_output': 'accuracy',\n",
    "                       'eyes_output':'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnRnEcWB3gb2",
    "outputId": "9f00a00e-dfb0-4f86-9b40-c64144261ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - expression_output_accuracy: 0.2379 - expression_output_loss: 1.3895 - eyes_output_accuracy: 0.5456 - eyes_output_loss: 0.6868 - loss: 6.4280 - pose_output_accuracy: 0.2989 - pose_output_loss: 1.3725 - userid_output_accuracy: 0.0714 - userid_output_loss: 2.9791 - val_expression_output_accuracy: 0.2650 - val_expression_output_loss: 1.3840 - val_eyes_output_accuracy: 0.6389 - val_eyes_output_loss: 0.6203 - val_loss: 5.9783 - val_pose_output_accuracy: 0.4338 - val_pose_output_loss: 1.2417 - val_userid_output_accuracy: 0.1838 - val_userid_output_loss: 2.7216\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.2706 - expression_output_loss: 1.4016 - eyes_output_accuracy: 0.6834 - eyes_output_loss: 0.5968 - loss: 5.5581 - pose_output_accuracy: 0.4519 - pose_output_loss: 1.1958 - userid_output_accuracy: 0.2947 - userid_output_loss: 2.3636 - val_expression_output_accuracy: 0.2393 - val_expression_output_loss: 1.4581 - val_eyes_output_accuracy: 0.7628 - val_eyes_output_loss: 0.4652 - val_loss: 4.7767 - val_pose_output_accuracy: 0.4444 - val_pose_output_loss: 1.1435 - val_userid_output_accuracy: 0.4402 - val_userid_output_loss: 1.7002\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - expression_output_accuracy: 0.3203 - expression_output_loss: 1.3933 - eyes_output_accuracy: 0.7524 - eyes_output_loss: 0.4810 - loss: 4.3767 - pose_output_accuracy: 0.5004 - pose_output_loss: 1.1269 - userid_output_accuracy: 0.5521 - userid_output_loss: 1.3756 - val_expression_output_accuracy: 0.2094 - val_expression_output_loss: 1.5394 - val_eyes_output_accuracy: 0.7201 - val_eyes_output_loss: 0.5082 - val_loss: 4.3648 - val_pose_output_accuracy: 0.4722 - val_pose_output_loss: 1.1162 - val_userid_output_accuracy: 0.5641 - val_userid_output_loss: 1.1950\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.3296 - expression_output_loss: 1.3703 - eyes_output_accuracy: 0.8182 - eyes_output_loss: 0.3874 - loss: 3.5596 - pose_output_accuracy: 0.5755 - pose_output_loss: 0.9399 - userid_output_accuracy: 0.7260 - userid_output_loss: 0.8621 - val_expression_output_accuracy: 0.2222 - val_expression_output_loss: 1.5080 - val_eyes_output_accuracy: 0.7885 - val_eyes_output_loss: 0.4348 - val_loss: 4.0633 - val_pose_output_accuracy: 0.5577 - val_pose_output_loss: 1.0290 - val_userid_output_accuracy: 0.6239 - val_userid_output_loss: 1.0939\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - expression_output_accuracy: 0.3848 - expression_output_loss: 1.3120 - eyes_output_accuracy: 0.8207 - eyes_output_loss: 0.3810 - loss: 3.1991 - pose_output_accuracy: 0.6391 - pose_output_loss: 0.8565 - userid_output_accuracy: 0.8024 - userid_output_loss: 0.6496 - val_expression_output_accuracy: 0.2564 - val_expression_output_loss: 1.5275 - val_eyes_output_accuracy: 0.7756 - val_eyes_output_loss: 0.4329 - val_loss: 3.6670 - val_pose_output_accuracy: 0.5962 - val_pose_output_loss: 0.9683 - val_userid_output_accuracy: 0.7671 - val_userid_output_loss: 0.7477\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.3889 - expression_output_loss: 1.3256 - eyes_output_accuracy: 0.8704 - eyes_output_loss: 0.2908 - loss: 2.8156 - pose_output_accuracy: 0.6899 - pose_output_loss: 0.7457 - userid_output_accuracy: 0.8615 - userid_output_loss: 0.4534 - val_expression_output_accuracy: 0.1923 - val_expression_output_loss: 1.5620 - val_eyes_output_accuracy: 0.7735 - val_eyes_output_loss: 0.4699 - val_loss: 3.8499 - val_pose_output_accuracy: 0.5855 - val_pose_output_loss: 1.0330 - val_userid_output_accuracy: 0.7479 - val_userid_output_loss: 0.7991\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.4166 - expression_output_loss: 1.2547 - eyes_output_accuracy: 0.8760 - eyes_output_loss: 0.2678 - loss: 2.5351 - pose_output_accuracy: 0.7542 - pose_output_loss: 0.6467 - userid_output_accuracy: 0.8816 - userid_output_loss: 0.3658 - val_expression_output_accuracy: 0.2115 - val_expression_output_loss: 1.6229 - val_eyes_output_accuracy: 0.8141 - val_eyes_output_loss: 0.4093 - val_loss: 3.8366 - val_pose_output_accuracy: 0.5726 - val_pose_output_loss: 1.1406 - val_userid_output_accuracy: 0.7906 - val_userid_output_loss: 0.6770\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.4338 - expression_output_loss: 1.2190 - eyes_output_accuracy: 0.8945 - eyes_output_loss: 0.2522 - loss: 2.2553 - pose_output_accuracy: 0.7991 - pose_output_loss: 0.5220 - userid_output_accuracy: 0.9091 - userid_output_loss: 0.2620 - val_expression_output_accuracy: 0.2222 - val_expression_output_loss: 1.6260 - val_eyes_output_accuracy: 0.8034 - val_eyes_output_loss: 0.4363 - val_loss: 3.6394 - val_pose_output_accuracy: 0.6538 - val_pose_output_loss: 0.9381 - val_userid_output_accuracy: 0.8077 - val_userid_output_loss: 0.6684\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.4911 - expression_output_loss: 1.1614 - eyes_output_accuracy: 0.9158 - eyes_output_loss: 0.1870 - loss: 2.0384 - pose_output_accuracy: 0.7973 - pose_output_loss: 0.4927 - userid_output_accuracy: 0.9379 - userid_output_loss: 0.1974 - val_expression_output_accuracy: 0.2265 - val_expression_output_loss: 1.6578 - val_eyes_output_accuracy: 0.8141 - val_eyes_output_loss: 0.4425 - val_loss: 3.6779 - val_pose_output_accuracy: 0.6624 - val_pose_output_loss: 0.9618 - val_userid_output_accuracy: 0.8248 - val_userid_output_loss: 0.6343\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - expression_output_accuracy: 0.5160 - expression_output_loss: 1.1275 - eyes_output_accuracy: 0.9332 - eyes_output_loss: 0.1591 - loss: 1.8078 - pose_output_accuracy: 0.8523 - pose_output_loss: 0.3800 - userid_output_accuracy: 0.9588 - userid_output_loss: 0.1412 - val_expression_output_accuracy: 0.2073 - val_expression_output_loss: 1.7658 - val_eyes_output_accuracy: 0.8120 - val_eyes_output_loss: 0.4233 - val_loss: 3.8493 - val_pose_output_accuracy: 0.6410 - val_pose_output_loss: 1.0304 - val_userid_output_accuracy: 0.7885 - val_userid_output_loss: 0.6840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20eff613590>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "model.fit(\n",
    "    X_train,\n",
    "    {'userid_output': y_train_userid, \n",
    "     'pose_output': y_train_pose,\n",
    "     'expression_output': y_train_expression,\n",
    "     'eyes_output':y_train_eyes},\n",
    "    epochs=10, # can adjust\n",
    "    batch_size=32, # decrease batch size if you want to improve acc and increase compute time\n",
    "    validation_split=0.2 # internal validation split inside the neural network\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RbD5RK-34zb",
    "outputId": "8f1f67aa-8cba-409e-b10a-b34ab6d68d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - expression_output_accuracy: 0.1545 - expression_output_loss: 1.9101 - eyes_output_accuracy: 0.8639 - eyes_output_loss: 0.3529 - loss: 3.4327 - pose_output_accuracy: 0.7142 - pose_output_loss: 0.8746 - userid_output_accuracy: 0.9136 - userid_output_loss: 0.2943 \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "results = model.evaluate(np.array(X_test), {\n",
    "        'userid_output': y_test_userid,\n",
    "        'pose_output': y_test_pose,\n",
    "        'expression_output': y_test_expression,\n",
    "        'eyes_output': y_test_eyes\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
